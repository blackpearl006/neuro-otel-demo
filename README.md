# OpenTelemetry Observability Learning Project
### Neuroimaging Preprocessing with Full Stack Observability

A complete learning environment for understanding **OpenTelemetry**, **distributed tracing**, **metrics**, and **logging** using a simulated neuroimaging preprocessing pipeline.

---

## ğŸ¯ What Is This?

This project demonstrates **production-grade observability** for a Python application using:

- **OpenTelemetry** - Industry standard for instrumentation
- **Grafana** - Unified visualization dashboard
- **Prometheus** - Metrics storage and querying
- **Loki** - Log aggregation and search
- **Tempo** - Distributed tracing backend

**The Application**: A simulated brain scan preprocessing pipeline (load â†’ process â†’ write) that generates rich telemetry data for learning purposes.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User Interface (Grafana)            â”‚
â”‚         http://localhost:3000               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–²
                    â”‚ Queries
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ Tempo â”‚   â”‚ Loki  â”‚   â”‚Promethâ”‚
    â”‚ :3200 â”‚   â”‚ :3100 â”‚   â”‚ :9090 â”‚
    â””â”€â”€â”€â–²â”€â”€â”€â”˜   â””â”€â”€â”€â–²â”€â”€â”€â”˜   â””â”€â”€â”€â–²â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Exports
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OTel Collector       â”‚
        â”‚  :4317 (gRPC)         â”‚
        â”‚  :4318 (HTTP)         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ OTLP
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Preprocessing App    â”‚
        â”‚  (To be built)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start (5 Minutes)

### 1. Prerequisites

- **Docker Desktop** (macOS/Windows) or Docker + Docker Compose (Linux)
- **Python 3.10+**
- **Git**

### 2. Clone and Setup

```bash
# Clone the repository
git clone <your-repo-url>
cd neuro-otel-demo

# Install the Python application
cd app/
pip install -e .
cd ..

# Start the observability stack
docker-compose up -d

# Wait ~30 seconds for all services to be healthy
```

### 3. Run Your First Demo

```bash
# Generate sample data and process it
./scripts/run_demo.sh normal
```

### 4. View Telemetry in Grafana

Open **http://localhost:3000** (login: `admin` / `admin`)

- **Pre-built Dashboard**: http://localhost:3000/d/neuroimaging-pipeline
- **Explore Traces**: Explore â†’ Tempo â†’ Search for "neuro-preprocess"
- **Explore Logs**: Explore â†’ Loki â†’ Query: `{service_name="neuro-preprocess"}`
- **Explore Metrics**: Explore â†’ Prometheus â†’ Try: `neuro_files_processed_total`

## Directory Structure

```
neuro-otel-demo/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ plan.md                             # Comprehensive project plan
â”œâ”€â”€ docker-compose.yml                  # Orchestration configuration
â”‚
â”œâ”€â”€ containers/                         # Docker container definitions
â”‚   â”œâ”€â”€ Dockerfile.otel-collector
â”‚   â”œâ”€â”€ Dockerfile.prometheus
â”‚   â”œâ”€â”€ Dockerfile.loki
â”‚   â”œâ”€â”€ Dockerfile.tempo
â”‚   â”œâ”€â”€ Dockerfile.grafana
â”‚   â”œâ”€â”€ Dockerfile.app                  # Placeholder for Phase 3
â”‚   â””â”€â”€ build_all.sh                    # Build script
â”‚
â”œâ”€â”€ configs/                            # Service configurations
â”‚   â”œâ”€â”€ otel-collector-config.yaml      # Collector pipeline config
â”‚   â”œâ”€â”€ prometheus.yml                  # Scrape configuration
â”‚   â”œâ”€â”€ loki-config.yaml                # Log storage config
â”‚   â”œâ”€â”€ tempo-config.yaml               # Trace storage config
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ datasources.yaml            # Auto-provisioned datasources
â”‚       â””â”€â”€ dashboards/                 # Dashboard definitions (Phase 7)
â”‚
â””â”€â”€ data/                               # Runtime data (gitignored)
    â”œâ”€â”€ input/                          # Input scan files
    â”œâ”€â”€ output/                         # Processed outputs
    â””â”€â”€ telemetry/                      # Persistent storage
        â”œâ”€â”€ prometheus/                 # Time-series database
        â”œâ”€â”€ loki/                       # Log storage
        â”œâ”€â”€ tempo/                      # Trace storage
        â””â”€â”€ grafana/                    # Grafana database
```

## Service Details

### OpenTelemetry Collector

**Ports**: 4317 (gRPC), 4318 (HTTP), 8888 (metrics), 8889 (Prometheus exporter)

**Purpose**: Receives telemetry from applications, processes it, and exports to backends.

**Configuration**: `configs/otel-collector-config.yaml`

### Prometheus

**Port**: 9090

**Purpose**: Stores time-series metrics data and provides PromQL query interface.

**Configuration**: `configs/prometheus.yml`

**Data**: Persisted in Docker volume `prometheus-data`

### Loki

**Port**: 3100

**Purpose**: Aggregates logs with label-based indexing (like "grep for logs").

**Configuration**: `configs/loki-config.yaml`

**Data**: Persisted in Docker volume `loki-data`

### Tempo

**Ports**: 3200 (HTTP), 4317 (OTLP gRPC)

**Purpose**: Stores distributed traces with TraceQL query support.

**Configuration**: `configs/tempo-config.yaml`

**Data**: Persisted in Docker volume `tempo-data`

### Grafana

**Port**: 3000

**Purpose**: Unified visualization dashboard for metrics, logs, and traces.

**Default Login**: admin/admin (change on first login)

**Features**:
- Pre-configured datasources for Prometheus, Loki, Tempo
- Trace-to-logs correlation enabled
- Logs-to-trace correlation enabled

## Exploring the Stack

### In Grafana (http://localhost:3000)

1. **Explore Metrics**:
   - Navigate to Explore â†’ Select "Prometheus"
   - Try query: `up` (shows which services are running)

2. **Explore Logs**:
   - Navigate to Explore â†’ Select "Loki"
   - Try query: `{container_name="otel-collector"}`

3. **Explore Traces**:
   - Navigate to Explore â†’ Select "Tempo"
   - Search for traces (will be empty until app sends telemetry)

### Verify Data Flow

Check that the collector is receiving and exporting data:

```bash
# Check collector metrics
curl http://localhost:8888/metrics | grep otelcol_receiver

# Check Prometheus targets
curl http://localhost:9090/api/v1/targets

# Check Loki readiness
curl http://localhost:3100/ready

# Check Tempo readiness
curl http://localhost:3200/ready
```

## Troubleshooting

### Containers won't start

```bash
# Check logs for specific service
docker-compose logs <service-name>

# Common issues:
# - Port conflicts: Check if ports 3000, 3100, 3200, 4317, 9090 are available
# - Permission issues: Ensure data directories are writable
# - Resource limits: Ensure Docker has enough memory (4GB+ recommended)
```

### Port conflicts

If you see "port already in use" errors:

```bash
# Find what's using the port
lsof -i :3000

# Change ports in docker-compose.yml if needed
# Example: "3001:3000" to map container port 3000 to host port 3001
```

### Reset everything

```bash
# Stop and remove all containers and volumes
docker-compose down -v

# Rebuild from scratch
cd containers && ./build_all.sh
docker-compose up -d
```

### Grafana can't connect to datasources

1. Check that all services are running: `docker-compose ps`
2. Check service names match in `configs/grafana/datasources.yaml`
3. Verify network connectivity: `docker-compose exec grafana ping prometheus`

## Converting to Apptainer (Future)

This project currently uses Docker for macOS compatibility. To convert to Apptainer for HPC/nipoppy integration:

1. **Create `.def` files** from Dockerfiles:
   - Use `Bootstrap: docker` and `From:` directives
   - Convert `LABEL` to `%labels` section
   - Convert `CMD` to `%runscript`

2. **Build SIF images**:
   ```bash
   apptainer build otel-collector.sif otel-collector.def
   ```

3. **Replace docker-compose** with launch script:
   ```bash
   apptainer instance start \
     --bind configs/otel-collector-config.yaml:/etc/otelcol/config.yaml \
     otel-collector.sif otel-collector
   ```

4. **Networking**: Apptainer shares host network by default (similar to Docker host mode)


## Resources

- [OpenTelemetry Docs](https://opentelemetry.io/docs/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Loki Documentation](https://grafana.com/docs/loki/)
- [Grafana Tempo Documentation](https://grafana.com/docs/tempo/)
- [Grafana Documentation](https://grafana.com/docs/grafana/latest/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)
